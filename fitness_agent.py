import os
import re
import gradio as gr
from typing import Annotated, Literal, List, Dict


from pydantic import BaseModel, Field
from langchain_core.runnables import RunnablePassthrough
from langchain_core.messages import AnyMessage, HumanMessage
from langgraph.graph.message import add_messages
from langchain_core.tools import tool

from langchain_openai import ChatOpenAI
from langchain_community.tools import TavilySearchResults
from langchain_core.prompts import PromptTemplate


from langgraph.graph import StateGraph, START, END
from dotenv import load_dotenv

load_dotenv()

os.environ['OPENAI_API_KEY']=os.getenv("OPENAI_API_KEY")
os.environ["TAVILY_API_KEY"] = os.getenv("TAVILY_API_KEY")

# Initialize LLM and the search tool
llm = ChatOpenAI(model="gpt-4o", temperature=0)
search_tool = TavilySearchResults(max_results=5) # Configure to return a few top results

## --- State Definition ---
class WorkoutAgentState(BaseModel):
    """
    Represents the state of the workout agent as a Pydantic model.
    """
    user_query: str = Field(..., description="The user's initial query or request.")
    medical_history: str = Field(..., description="The user's medical history for a safe workout plan.")
    generated_plan: str = Field(..., description="The workout plan generated by the LLM.")
    final_plan: str = Field(..., description="The final, user-approved workout plan.")
    messages: Annotated[List[AnyMessage], add_messages] = Field(
        ...,
        description="The message history for the conversation, annotated for LangGraph."
    )
    
## --- Node Definitions ---

# Node 1: Generates a workout plan based on a direct search
def generate_workout_plan(state: WorkoutAgentState) -> dict:
    """Generates a workout plan using a search-augmented chain."""
    user_query = state.user_query
    
    print("üß† Searching the internet and generating a workout plan...")
    
    # Create a search query to find workout plans
    search_query = f"workout plan for {user_query}"
    search_results = search_tool.invoke({"query": search_query})
    
    # Use the search results to generate a comprehensive plan
    plan_prompt = PromptTemplate.from_template("""
        You are a professional fitness coach. The user wants a workout plan based on their request.
        
        User Request: {user_query}
        
        <context>
        Relevant information from the internet:
        {context}
        </context>

        Based on the provided context, create a detailed 4-week workout plan. 
        Structure the plan clearly with days, exercises, sets, and reps.
        Do not include any medical advice.
    """)
    
    plan_chain = (
        {"user_query": RunnablePassthrough(), "context": RunnablePassthrough()}
        | plan_prompt
        | llm
    )
    
    response = plan_chain.invoke({
        "user_query": user_query,
        "context": search_results
    })
    
    return {"generated_plan": response.content}

# Node 2: Evaluates the plan against medical history using a search tool
def evaluate_and_modify_plan(state: WorkoutAgentState) -> dict:
    """
    Evaluates the plan against medical history using a search tool
    and suggests alternatives based on the findings.
    """
    generated_plan = state.generated_plan
    medical_history = state.medical_history
    
    print("üë©‚Äç‚öïÔ∏è Evaluating the generated plan for safety with external search...")
    
    # Create a search query based on the plan and medical history
    search_query = f"Are any exercises in '{generated_plan}' not recommended for someone with a medical history of '{medical_history}'? Provide safe alternatives."
    
    # Run the search and get results
    print(f"üîç Searching for: {search_query}")
    search_results = search_tool.invoke({"query": search_query})
    
    evaluator_prompt = PromptTemplate.from_template("""
        You are a professional fitness coach and a physical therapist.
        The user has a workout plan and a medical history.

        Medical History: {medical_history}

        Workout Plan:
        {plan}
        
        <context>
        Relevant search results for safety evaluation:
        {context}
        </context>

        Critically review the workout plan. Using the provided context,
        explain if any exercise could be harmful given the user's medical history.
        Suggest a safe, alternative exercise that targets the same muscle group if needed.
        If the plan is safe and suitable, simply confirm that it is safe to proceed.
        Provide a final, concise recommendation.
    """)
    
    evaluator_chain = (
        {"plan": RunnablePassthrough(), "medical_history": RunnablePassthrough(), "context": RunnablePassthrough()}
        | evaluator_prompt | llm
    )
    
    evaluation_result = evaluator_chain.invoke({
        "plan": generated_plan,
        "medical_history": medical_history,
        "context": search_results
    })
    
    final_plan = f"Workout Plan: \n\n{generated_plan}\n\nSafety Evaluation:\n{evaluation_result.content}"
    
    return {"final_plan": final_plan}

## --- Conditional Logic ---
def should_evaluate(state: WorkoutAgentState) -> Literal["evaluate", "end"]:
    """Determines whether to route to the evaluator node or end."""
    if state.medical_history:
        print("üîç Medical history found. Routing to evaluator...")
        return "evaluate"
    else:
        print("üëç No medical history provided. Skipping evaluation.")
        return "end"

## --- Build and Compile the LangGraph ---
def build_agent_graph():
    """Builds and compiles the LangGraph."""
    workflow = StateGraph(WorkoutAgentState)
    
    # Add nodes
    workflow.add_node("generate", generate_workout_plan)
    workflow.add_node("evaluate", evaluate_and_modify_plan)
    
    # Define edges
    workflow.add_edge(START, "generate")
    workflow.add_conditional_edges(
        "generate",
        should_evaluate,
        {"evaluate": "evaluate", "end": END}
    )
    workflow.add_edge("evaluate", END)
    
    # Compile the graph
    app = workflow.compile()
    print("üöÄ LangGraph agent compiled successfully!")
    return app
    
# --- Gradio Interface ---
# This function acts as the interface between Gradio and the LangGraph agent
def run_agent_flow(user_query, medical_history):
    """Runs the LangGraph agent with user inputs."""
    # Ensure medical_history is not None
    medical_history = medical_history or ""
    
    # Initialize the agent
    agent_app = build_agent_graph()
    
    # Prepare the initial state
    inputs = {
        "user_query": user_query,
        "medical_history": medical_history,
        "generated_plan": "",
        "final_plan": "",
        "messages": [HumanMessage(content=user_query)]
    }
    
    # Invoke the agent's graph
    result = agent_app.invoke(inputs)
    
    # Determine which output to return based on the flow
    if 'final_plan' in result and result['final_plan']:
        return result['final_plan']
    elif 'generated_plan' in result and result['generated_plan']:
        return result['generated_plan']
    else:
        return "Failed to generate a workout plan. Please try again."

# Create the Gradio interface
iface = gr.Interface(
    fn=run_agent_flow,
    inputs=[
        gr.Textbox(
            label="Workout Request",
            placeholder="e.g., I want a workout routine for muscle gain using dumbbells."
        ),
        gr.Textbox(
            label="Medical History (Optional)",
            placeholder="e.g., I have lower back pain and a bad knee."
        )
    ],
    outputs=gr.Textbox(label="Workout Plan"),
    title="AI-Powered Workout Planner",
    description=(
        "Enter your workout goals and any relevant medical history. "
        "The AI will generate a personalized plan and evaluate it for safety."
    ),
    
    # Add a loading message to let the user know the process is running
    live=False, # Disable live updates for better performance on long-running tasks
)

# Launch the Gradio app
if __name__ == "__main__":
    iface.launch(server_name="localhost", server_port=7860)
